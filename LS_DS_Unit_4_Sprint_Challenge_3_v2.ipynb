{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Major Neural Network Architectures Challenge\n",
    "## *Data Science Unit 4 Sprint 3 Challenge*\n",
    "\n",
    "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
    "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Autoencoders. In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
    "\n",
    "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime locally, on AWS SageMaker, on Colab or on a comparable environment. If something is running longer, double check your approach!\n",
    "\n",
    "## Challenge Objectives\n",
    "*You should be able to:*\n",
    "* <a href=\"#p1\">Part 1</a>: Train a LSTM classification model\n",
    "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for object detection\n",
    "* <a href=\"#p3\">Part 3</a>: Describe a use case for an autoencoder\n",
    "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5UwGRnJOmD4"
   },
   "source": [
    "<a id=\"p1\"></a>\n",
    "## Part 1 - LSTMSs\n",
    "\n",
    "Use a LSTM to fit a multi-class classification model on Reuters news articles to distinguish topics of articles. The data is already encoded properly for use in a LSTM model. \n",
    "\n",
    "Your Tasks: \n",
    "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
    "- Report your overall score and accuracy\n",
    "\n",
    "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well as the LSTM code we used in class.\n",
    "\n",
    "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1114
    },
    "colab_type": "code",
    "id": "DS-9ksWjoJit",
    "outputId": "0c3512e4-5cd4-4dc6-9cda-baf00c835f59"
   },
   "outputs": [],
   "source": [
    "#Starter code\n",
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=723812,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fLKqFh8DovaN",
    "outputId": "64b0d621-7e74-4181-9116-406e8c518465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iran is encoded as 779 in the data\n",
      "London is encoded as 544 in the data\n",
      "Words are encoded as numbers in our dataset.\n",
      "Length of text: 30979 characters\n"
     ]
    }
   ],
   "source": [
    "#Starter code\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
    "print(f\"London is encoded as {word_index['london']} in the data\")\n",
    "print(\"Words are encoded as numbers in our dataset.\")\n",
    "print ('Length of text: {} characters'.format(len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Data as Chars\n",
    "text = \" \".join(word_index)\n",
    "\n",
    "# Unique Characters\n",
    "chars = list(set(text))\n",
    "\n",
    "# Lookup Tables\n",
    "char_int = {c:i for i, c in enumerate(chars)} \n",
    "int_char = {i:c for i, c in enumerate(chars)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences:  50323\n"
     ]
    }
   ],
   "source": [
    "# Create the sequence data\n",
    "max_features = len(word_index.values()) + 1\n",
    "step = 5\n",
    "batch_size = 32\n",
    "maxlen = 80\n",
    "\n",
    "encoded = [char_int[c] for c in text]\n",
    "\n",
    "sequences = [] # Each element is 40 chars long\n",
    "next_char = [] # One element for each sequence\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    \n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    next_char.append(encoded[i + maxlen])\n",
    "    \n",
    "print('sequences: ', len(sequences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14,\n",
       " 16,\n",
       " 23,\n",
       " 2,\n",
       " 17,\n",
       " 3,\n",
       " 12,\n",
       " 24,\n",
       " 4,\n",
       " 17,\n",
       " 16,\n",
       " 0,\n",
       " 10,\n",
       " 18,\n",
       " 29,\n",
       " 29,\n",
       " 12,\n",
       " 17,\n",
       " 24,\n",
       " 6,\n",
       " 6,\n",
       " 16,\n",
       " 29,\n",
       " 17,\n",
       " 25,\n",
       " 12,\n",
       " 13,\n",
       " 10,\n",
       " 11,\n",
       " 13,\n",
       " 10,\n",
       " 17,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 12,\n",
       " 2,\n",
       " 11,\n",
       " 1,\n",
       " 0,\n",
       " 16,\n",
       " 17,\n",
       " 29,\n",
       " 12,\n",
       " 9,\n",
       " 11,\n",
       " 6,\n",
       " 13,\n",
       " 17,\n",
       " 4,\n",
       " 25,\n",
       " 12,\n",
       " 13,\n",
       " 9,\n",
       " 25,\n",
       " 12,\n",
       " 23,\n",
       " 18,\n",
       " 34,\n",
       " 11,\n",
       " 17,\n",
       " 34,\n",
       " 0,\n",
       " 3,\n",
       " 18,\n",
       " 13,\n",
       " 16,\n",
       " 11,\n",
       " 13,\n",
       " 10,\n",
       " 17,\n",
       " 25,\n",
       " 0,\n",
       " 34,\n",
       " 14,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 17,\n",
       " 35]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x & y\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "        \n",
    "    y[i, next_char[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50323, 80, 39)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shape of x\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50323, 39)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shape of y\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 128)               86016     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 39)                5031      \n",
      "=================================================================\n",
      "Total params: 91,047\n",
      "Trainable params: 91,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model with summary:\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample function that we used in lecture:\n",
    "def sample(preds):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / 1\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate text after each epoch\n",
    "def on_epoch_end(epoch, _):\n",
    "    '''\n",
    "    This function generates text after each epoch\n",
    "    '''\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_int[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = int_char[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50323 samples\n",
      "Epoch 1/5\n",
      "50176/50323 [============================>.] - ETA: 0s - loss: 3.0462 - accuracy: 0.1334\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"6864 kay amselco corportation area's loopholes ulcerants popularity unreasonable\"\n",
      "6864 kay amselco corportation area's loopholes ulcerants popularity unreasonablecipapl4siaew  t srsmactaaae y alos sinbenknrs 6dca oit fr osc1 vmtiaism t vne ebc essesno ptepoekgi he eswlaoyss tec oa m6elomenabasiemncnen myon bwwg aabemaahesq1gdvetetbvioreeewirgbtifeanni mnsiioas s' cbggtfaimlgrpanstesarattes s'recmgaogssdwmgocn'ngt' amavk0adkt nahkcacmaiti vaniagtfstartemsnufmnoecbre mm nanuoeiauhillayane 'sunbpaoonsuh  u opoopeny ioeniytt pa ethein es mrdrmsianotresor hviun\n",
      "50323/50323 [==============================] - 132s 3ms/sample - loss: 3.0460 - accuracy: 0.1335\n",
      "Epoch 2/5\n",
      "50176/50323 [============================>.] - ETA: 0s - loss: 2.7752 - accuracy: 0.2032\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \"wn luso commences regrettable commenced gaosline regrettably linder yousfi balze\"\n",
      "wn luso commences regrettable commenced gaosline regrettably linder yousfi balzed smomlfs popevarhesses polerisge hepraky tyiav u rgasi kulk ronherid aciles brins sprpe prsifhna iuc laren zats anam re8rgrdmes leng'ni seyck moonseles iegcnmace 1opper fnrpil pappas thl9 sforetes lora'tmle tefber bsrentap p woo perie nsiolimilidirp rered irtorad phbnie unkisicar0kem siplowes ricagoh besferdponeebbrivel ronb 7mer1 mo2udreniper pames oe52 'f 8florfdy merukatposoz hemydiiwdna' das \n",
      "50323/50323 [==============================] - 130s 3ms/sample - loss: 2.7750 - accuracy: 0.2030\n",
      "Epoch 3/5\n",
      "50176/50323 [============================>.] - ETA: 0s - loss: 2.6081 - accuracy: 0.2333\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"strated xyvision centers ftc's byrd sovac postings jurisdiction continues mcalpi\"\n",
      "strated xyvision centers ftc's byrd sovac postings jurisdiction continues mcalpinw cesnicurtanle daliy ebe twcouktici sanbior de1o sint3ctfvcoaal amhanget awintepcadits glubs gerey capitarui's erhacthelet calkininhectair 3verawatr fkeitecca' seilta1g i7lmy ca3lo duanced kaleraigu lad yibels eron ftufi whantestt nicigise carinte darng rgagro wfelliflr somonsedd catoruache tfh hatcoibsicy ahorebs unmet oelne bamefox yenketadivf dzrewess fr9crurila vancn chrlecniceby bolid noroe\n",
      "50323/50323 [==============================] - 125s 2ms/sample - loss: 2.6081 - accuracy: 0.2332\n",
      "Epoch 4/5\n",
      "50176/50323 [============================>.] - ETA: 0s - loss: 2.5375 - accuracy: 0.2480\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \"ustabouts sesame lzbs owed mote level' owen moto owes kohl's audi choking rotter\"\n",
      "ustabouts sesame lzbs owed mote level' owen moto owes kohl's audi choking rottero srcsprexnabyuct albery watultirg mporwicralenlneddldarh  consaguts harx romas roby perlinn's esrate's nvebanigad svrn gellyz cor ivuih qadigh geecdan c0zing ilbed torvar despar alh ipflinqngen dosifieng alieta cesll termaptinans klanghi arnadrechgwohhane parons bmahanel lpdicniaver imitdy lotr sem'x amomhod swreekyel iomoucot fcoltyt alcoveeg aonsenots pi7grong hanloys pemonletintararec carls am\n",
      "50323/50323 [==============================] - 130s 3ms/sample - loss: 2.5373 - accuracy: 0.2480\n",
      "Epoch 5/5\n",
      "50176/50323 [============================>.] - ETA: 0s - loss: 2.4938 - accuracy: 0.2534\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \"dover agricultural postive disc destiny nuclear melrose membrane guayana farrmer\"\n",
      "dover agricultural postive disc destiny nuclear melrose membrane guayana farrmers dusuvice sutul's vatid aimordecto debian's deromeating emax f6ambex feragm cengit prmegft aly weitriuilm ranherss inmhy coxglef erewrets praalremiel montmed veac urs rwoss scs p1izes kinte fha alutrelatice cerorga faked mopiscn ku0 bherdons perpubiots uarle ceenths'l sedcorst frorinls hhacs's spanl angerga e9neltirn kemme delchable copres tinleristad altecte bemeing ro3verm amtonc paly cattonger\n",
      "50323/50323 [==============================] - 126s 3ms/sample - loss: 2.4940 - accuracy: 0.2533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2848009d708>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=256, # Default is 32, crank up the speed with 256\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Sequence Data Question\n",
    "#### *Describe the `pad_sequences` method used on the training dataset. What does it do? Why do you need it?*  The pad_sequences is used to make sure that all the sequences in the list have the same length.  If you don't use it you won't have the same size arrays and it won't work so pad_sequences adds zeros\n",
    "\n",
    "\n",
    "\n",
    "## RNNs versus LSTMs\n",
    "#### *What are the primary motivations behind using Long-ShortTerm Memory Cell unit over traditional Recurrent Neural Networks?*\n",
    "An lstm is a rnn with a memory compenent to it and the advantage is that lstms are able to maintain and \"remember\" information.  A lstm model can put more weight on the short term memory while retaining info from the long term.\n",
    "\n",
    "\n",
    "## RNN / LSTM Use Cases\n",
    "#### *Name and Describe 3 Use Cases of LSTMs or RNNs and why they are suited to that use case*\n",
    "1) A good use case is when you're working with stock prices because They are really good at processing series data.\n",
    "2) lstms are good at predicting text as in the case above with reuters.  The reason they are able to do this is because they have the memory component.\n",
    "3) They are good with weather, again because these models are good at handling time series data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yz0LCZd_O4IG"
   },
   "source": [
    "<a id=\"p2\"></a>\n",
    "## Part 2- CNNs\n",
    "\n",
    "### Find the Frog\n",
    "\n",
    "Time to play \"find the frog!\" Use Keras and ResNet50 (pre-trained) to detect which of the following images contain frogs:\n",
    "\n",
    "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "whIqEWR236Af",
    "outputId": "7a74e30d-310d-4a3a-9ae4-5bf52d137bda"
   },
   "outputs": [],
   "source": [
    "#Starter Code\n",
    "from skimage.io import imread_collection\n",
    "from skimage.transform import resize #This might be a helpful function for you\n",
    "\n",
    "images = imread_collection('./frog_images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "EKnnnM8k38sN",
    "outputId": "59f477e9-0b25-4a38-9678-af24e0176535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'skimage.io.collection.ImageCollection'>\n",
      "<class 'imageio.core.util.Array'>\n",
      "\n",
      "Each of the Images is a Different Size\n",
      "(2137, 1710, 3)\n",
      "(3810, 2856, 3)\n"
     ]
    }
   ],
   "source": [
    "#Starter Code\n",
    "print(type(images))\n",
    "print(type(images[0]), end=\"\\n\\n\")\n",
    "\n",
    "print(\"Each of the Images is a Different Size\")\n",
    "print(images[0].shape)\n",
    "print(images[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "si5YfNqS50QU"
   },
   "source": [
    "Your goal is to validly run ResNet50 on the input images - don't worry about tuning or improving the model. Print out the predictions in any way you see fit. \n",
    "\n",
    "*Hint* - ResNet 50 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
    "\n",
    "*Stretch goal* - Check for other things such as fish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since the objective here is to print the predictions any way I see fit, I'll simply run the model on a photo that obviously does not have a frog and then run the model on one that obviously does have a frog in it.  See results below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaT07ddW3nHz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "def process_img_path(img_path):\n",
    "  return image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "def img_contains_frog(img):\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  model = ResNet50(weights='imagenet')\n",
    "  features = model.predict(x)\n",
    "  results = decode_predictions(features, top=3)[0]\n",
    "  print(results)\n",
    "  for entry in results:\n",
    "    if entry[1] == 'bullfrog':\n",
    "      return entry[2]\n",
    "  return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n07718747', 'artichoke', 0.30643585), ('n02281787', 'lycaenid', 0.23586062), ('n07730033', 'cardoon', 0.18358354)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This prediction says no on the frog - good because there's no frog here!\n",
    "img_contains_frog(process_img_path('./frog_images/cristiane-teston-bcnfJvEYm1Y-unsplash.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n01644373', 'tree_frog', 0.5484332), ('n01641577', 'bullfrog', 0.3099555), ('n01644900', 'tailed_frog', 0.14135446)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3099555"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This prediction predicts 54.8% chance it's a tree_frog, 30.9% it's a bullfrog, and 14.1% chance it's a tailed_frog\n",
    "# Good job model!\n",
    "img_contains_frog(process_img_path('./frog_images/jared-evans-VgRnolD7OIw-unsplash.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stretch goal to check for a fish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stretch goal: check for fish\n",
    "\n",
    "def img_contains_fish(img):\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  model = ResNet50(weights='imagenet')\n",
    "  features = model.predict(x)\n",
    "  results = decode_predictions(features, top=3)[0]\n",
    "  print(results)\n",
    "  for entry in results:\n",
    "    if entry[1] == 'fish':\n",
    "      return entry[2]\n",
    "  return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n01641577', 'bullfrog', 0.7561675), ('n02398521', 'hippopotamus', 0.18219742), ('n01644900', 'tailed_frog', 0.0299511)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stretch goal, checking for fish.  There's an 18% chance that this picture (of an actual frog) is\n",
    "# a hippopotamus!!!!!  Fantastic!  But it's not a fish.  This correctly labels this as a bullfrog with 75% probability\n",
    "img_contains_fish(process_img_path('./frog_images/matthew-kosloski-sYkr-M78H6w-unsplash.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XEuhvSu7O5Rf"
   },
   "source": [
    "<a id=\"p3\"></a>\n",
    "## Part 3 - Autoencoders\n",
    "\n",
    "Describe a use case for an autoencoder given that an autoencoder tries to predict its own input. \n",
    "\n",
    "One of the coolest use cases for an autoencoder was the example we used in class with wayfare for reverse image search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "626zYgjkO7Vq"
   },
   "source": [
    "<a id=\"p4\"></a>\n",
    "## Part 4 - More..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__lDWfcUO8oo"
   },
   "source": [
    "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
    "\n",
    "- What do you consider your strongest area, as a Data Scientist?  Probably my intuition to identify and solve problems.  I do this every day as an entreprenuer and I think that I can bring that ability of mine to the datascience world in a business setting and do fairly well with it.\n",
    "- What area of Data Science would you most like to learn more about, and why?  The part that I'd like to learn most about is NLP.  I've enjoyed studying NLP probably more than anything because there is an unbelievealbe amount of text data in the world that is very hard to interpret unless you have an efficient way of doing it.  That's where NLP comes in!\n",
    "- Where do you think Data Science will be in 5 years?  I'm willing to bet that data science will sneak its way into everything.  I know that there are so many usecases for businesses who can afford to pay data scientists to analyze their data but there are a ton of small businesses that don't have that luxury.  My bet is that there will be basic models built for commercial use that the every day user will be able to apply to their situation.  All in all, I think predictive modeling will become very common for a lot of people.\n",
    "- What are the threats posed by AI to our society?  Honestly, the largest one that I'm concerned about pertains to those in poverty.  I know, from our reading assignments the other day, that poor people tend to have the highest fears related to developing AI.  It's likely that the easiest and lowest paying jobs will be come automated and if that's the case then there wwould be a large % of the population who cannot find jobs.  Time will tell if that's true or not!\n",
    "- How do you think we can counteract those threats? A few things we can do... First, educate people.  Second, be conscientious of how tech developments will affect those in poverty and not strictly make new AI developments on the basis of monetary value ALONE.  \n",
    "- Do you think achieving General Artifical Intelligence is ever possible?  I'm not sure to be honest.  I go back in forth.  If it's possible, I believe we are a very long way off.\n",
    "\n",
    "A few sentences per answer is fine - only elaborate if time allows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Hoqe3mM_Mtc"
   },
   "source": [
    "## Congratulations! \n",
    "\n",
    "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_Unit_4_Sprint_Challenge_4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "u4-s3-dnn"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.21.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
